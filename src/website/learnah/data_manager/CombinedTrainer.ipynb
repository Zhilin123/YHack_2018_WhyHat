{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-12-01 19:22:26,369 : INFO : 'pattern' package found; tag filters are available for English\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from ast import literal_eval\n",
    "from gensim import corpora, models, similarities\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from stop_words import get_stop_words\n",
    "from random import shuffle\n",
    "import stop_words\n",
    "from gensim.parsing.porter import PorterStemmer\n",
    "import time\n",
    "import re\n",
    "import json, os, pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from TextCleaner import TextCleaner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class SubjectTrainer():\n",
    "    \"\"\"\n",
    "    The class for training topic model\n",
    "    \"\"\"\n",
    "    def __init__(self, folder=\"./subject_models\", cl_folder=\"../text_cleaner_models_with_subjects/\"):\n",
    "        \"\"\"\n",
    "        Initialize\n",
    "        \"\"\"\n",
    "        # init model folder\n",
    "        self.folder = folder\n",
    "        try:\n",
    "            os.mkdir(folder)\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        # load string cleaner\n",
    "        self.cl = TextCleaner(folder=cl_folder)\n",
    "        \n",
    "        # init index model variables\n",
    "        self.model = None\n",
    "        self.dictionary = None\n",
    "        \n",
    "        # topic index: topic_name . topic_index\n",
    "        self.topic_index = {}\n",
    "        \n",
    "        # indexed topic: topic_index . topic_name\n",
    "        self.indexed_topic = []\n",
    "        \n",
    "        # topic vec: topic_index . topic_model_vec\n",
    "        self.topic_vec = None\n",
    "        \n",
    "        # video index: video_name . video_index\n",
    "        self.video_index = {}\n",
    "        \n",
    "        # indexed video: video_index . video_name\n",
    "        self.indexed_video = []\n",
    "        \n",
    "        # video topic vec: video_index . topic_vec\n",
    "        self.video_topic_vec = {}\n",
    "        \n",
    "        # video vec: video_index . topic_model_vec\n",
    "        self.video_vec = {}\n",
    "        \n",
    "    def train_topic_model(self, cleaned_docs, vec_len=150):\n",
    "        \"\"\"\n",
    "        Train topic model and save the:\n",
    "        model, tfidf and dictionary model\n",
    "        \"\"\"\n",
    "        print(\"start training topic model\")\n",
    "        \n",
    "        # init topic model vector length\n",
    "        self.vec_len = vec_len\n",
    "        \n",
    "        # get dictionary\n",
    "        self.dictionary = corpora.Dictionary([doc.split() for doc in cleaned_docs])\n",
    "        \n",
    "        # remove organization specific words\n",
    "        self.dictionary.filter_extremes(no_below=5, no_above=0.5)\n",
    "        self.dictionary.compactify()\n",
    "        print(\"dicionary collected\")\n",
    "        \n",
    "        # prepare topic model\n",
    "        bows = [self.dictionary.doc2bow(doc.split()) for doc in cleaned_docs]\n",
    "        self.model = models.LdaModel(bows, self.vec_len, id2word=self.dictionary, chunksize=2000, passes=50, \n",
    "                                         iterations=100, alpha=\"auto\", eta=\"auto\", eval_every=80000\n",
    "                                        )\n",
    "        print(\"topic model generated\")\n",
    "        \n",
    "        # save to file\n",
    "        self.dictionary.save(self.folder + \"/\" + \"dictionary\")\n",
    "        self.model.save(self.folder + \"/\" + \"model\")\n",
    "        \n",
    "    def index_topic_and_video(self, topics, videos, existing_video_index=None):\n",
    "        \"\"\"\n",
    "        Index all documents to get self: topic_index, topic_vec, video_topic_vec and video_vec\n",
    "        \n",
    "        topics: dictionary of topic name and topic texts\n",
    "        videos: dictionary of video name and video subtitles\n",
    "        \"\"\" \n",
    "        # create video_index and indexed_video if no existing video index and indexed video\n",
    "        if existing_video_index is None:\n",
    "            v_counter = 0\n",
    "            for v in videos:\n",
    "                self.video_index[v] = v_counter\n",
    "                self.indexed_video.append(v)\n",
    "                v_counter += 1\n",
    "        else: # load existing video index\n",
    "            self.video_index = existing_video_index[\"video_index\"]\n",
    "            self.indexed_video = existing_video_index[\"indexed_video\"]\n",
    "            v_counter = len(self.indexed_video)\n",
    "        \n",
    "        # create topic_index and indexed_topic\n",
    "        t_counter = 0\n",
    "        for t in topics:\n",
    "            self.topic_index[t] = t_counter\n",
    "            self.indexed_topic.append(t)\n",
    "            t_counter += 1\n",
    "        \n",
    "        # create topic_vec\n",
    "        self.topic_vec = np.zeros((t_counter, self.vec_len))\n",
    "        for t in topics:\n",
    "            t_vec = self.index_text(topics[t], norm=None, thresh=30)\n",
    "            self.topic_vec[self.topic_index[t], :] = t_vec\n",
    "            \n",
    "        # create video_vec:\n",
    "        self.video_vec = np.zeros((v_counter, self.vec_len))\n",
    "        for v in videos:\n",
    "            v_vec = self.index_text(videos[v], norm=None, thresh=1)\n",
    "            self.video_vec[self.video_index[v], :] = v_vec\n",
    "            \n",
    "        # create video_topic_vec, preserve the original similarity score\n",
    "        self.video_topic_vec = self.norm_dot(self.video_vec, self.topic_vec)\n",
    "\n",
    "        # save self. topic_index, indexed_topic, topic_vec, video_index, indexed_video, video_vec, video_topic_vec\n",
    "        np.save(self.folder + \"/topic_vec\", self.topic_vec)\n",
    "        np.save(self.folder + \"/video_vec\", self.video_vec)\n",
    "        np.save(self.folder + \"/video_topic_vec\", self.video_topic_vec)\n",
    "        with open(self.folder + \"/topic_index.pkl\", 'wb') as f:\n",
    "            pickle.dump(self.topic_index, f)\n",
    "        with open(self.folder + \"/indexed_topic.pkl\", 'wb') as f:\n",
    "            pickle.dump(self.indexed_topic, f)\n",
    "        with open(self.folder + \"/video_index.pkl\", 'wb') as f:\n",
    "            pickle.dump(self.video_index, f)\n",
    "        with open(self.folder + \"/indexed_video.pkl\", 'wb') as f:\n",
    "            pickle.dump(self.indexed_video, f)\n",
    "    \n",
    "    def load_topic_model(self):\n",
    "        \"\"\"\n",
    "        load topic models if no training is needed\n",
    "        \"\"\"\n",
    "        self.dictionary = corpora.Dictionary.load(self.folder + \"/dictionary\")\n",
    "        self.model = models.LdaModel.load(self.folder + \"/model\")\n",
    "        self.vec_len = self.model.num_topics\n",
    "        \n",
    "    def load_topic_video_model(self):\n",
    "        \"\"\"\n",
    "        load topic_index, indexed_topic, topic_vec, video_index, indexed_video, video_vec, video_topic_vec\n",
    "        \"\"\"\n",
    "        self.topic_vec = np.load(self.folder + \"/topic_vec.npy\")\n",
    "        self.video_vec = np.load(self.folder + \"/video_vec.npy\")\n",
    "        self.video_topic_vec = np.load(self.folder + \"/video_topic_vec.npy\")\n",
    "        with open(self.folder + \"/topic_index.pkl\", 'rb') as f:\n",
    "            self.topic_index = pickle.load(f)\n",
    "        with open(self.folder + \"/indexed_topic.pkl\", 'rb') as f:\n",
    "            self.indexed_topic = pickle.load(f)\n",
    "        with open(self.folder + \"/video_index.pkl\", 'rb') as f:\n",
    "            self.video_index = pickle.load(f)\n",
    "        with open(self.folder + \"/indexed_video.pkl\", 'rb') as f:\n",
    "            self.indexed_video = pickle.load(f)\n",
    "        \n",
    "    def index_text(self, text, norm=None, thresh=0.05):\n",
    "        \"\"\"\n",
    "        Index a given string use topic model\n",
    "        \"\"\"\n",
    "        # clean the text\n",
    "        cleaned_text = self.cl.clean(text)\n",
    "\n",
    "        # get topic model index\n",
    "        model_vec = self.model.inference([self.dictionary.doc2bow(cleaned_text.split())])[0][0]\n",
    "        \n",
    "        # topics that has prob lower than thresh would be set to zero\n",
    "        model_vec -= thresh\n",
    "        model_vec[model_vec<0] = 0\n",
    "        \n",
    "        # return zero array if no significant topic possibility\n",
    "        if model_vec.sum() == 0:\n",
    "            return model_vec\n",
    "        \n",
    "        # do norm if necessary\n",
    "        if norm is None:\n",
    "            return model_vec\n",
    "        else:\n",
    "            return model_vec / np.linalg.norm(model_vec, ord=norm)\n",
    "        \n",
    "    def norm_dot(self, a, b):\n",
    "        \"\"\"\n",
    "        A dot operation that is aim to find all cos similarity of each row of each array\n",
    "        \"\"\"\n",
    "        # get per row norm for each array\n",
    "        norm_a = np.linalg.norm(a, ord=2, axis=1).reshape(-1, 1)\n",
    "        norm_b = np.linalg.norm(b, ord=2, axis=1).reshape(-1, 1)\n",
    "        \n",
    "        # get similarity by doting normalized array rows\n",
    "        sim = np.dot(a / norm_a, (b / norm_b).T)\n",
    "        \n",
    "        np.nan_to_num(sim, copy=False)\n",
    "        \n",
    "        return sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class InterestTrainer():\n",
    "    \"\"\"\n",
    "    The class for training topic model\n",
    "    \"\"\"\n",
    "    def __init__(self, folder=\"./asym_150_both\", cl_folder=\"../text_cleaner_models_without_subjects/\"):\n",
    "        \"\"\"\n",
    "        Initialize\n",
    "        \"\"\"\n",
    "        # init model folder\n",
    "        self.folder = folder\n",
    "        try:\n",
    "            os.mkdir(folder)\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        # load string cleaner\n",
    "        self.cl = TextCleaner(folder=cl_folder)\n",
    "        \n",
    "        # init index model variables\n",
    "        self.model = None\n",
    "        self.dictionary = None\n",
    "        \n",
    "        # topic index: topic_name . topic_index\n",
    "        self.topic_index = {}\n",
    "        \n",
    "        # indexed topic: topic_index . topic_name\n",
    "        self.indexed_topic = []\n",
    "        \n",
    "        # topic vec: topic_index . topic_model_vec\n",
    "        self.topic_vec = None\n",
    "        \n",
    "        # video index: video_name . video_index\n",
    "        self.video_index = {}\n",
    "        \n",
    "        # indexed video: video_index . video_name\n",
    "        self.indexed_video = []\n",
    "        \n",
    "        # video topic vec: video_index . topic_vec\n",
    "        self.video_topic_vec = {}\n",
    "        \n",
    "        # video vec: video_index . topic_model_vec\n",
    "        self.video_vec = {}\n",
    "        \n",
    "    def train_topic_model(self, cleaned_docs, vec_len=300):\n",
    "        \"\"\"\n",
    "        Train topic model and save the:\n",
    "        model, tfidf and dictionary model\n",
    "        \"\"\"\n",
    "        print(\"start training topic model\")\n",
    "        \n",
    "        # init topic model vector length\n",
    "        self.vec_len = vec_len\n",
    "        \n",
    "        # get dictionary\n",
    "        self.dictionary = corpora.Dictionary([doc.split() for doc in cleaned_docs])\n",
    "        \n",
    "        # remove organization specific words\n",
    "        self.dictionary.filter_extremes(no_below=10, no_above=0.35)\n",
    "        self.dictionary.compactify()\n",
    "        print(\"dicionary collected\")\n",
    "        \n",
    "        # prepare topic model\n",
    "        bows = [self.dictionary.doc2bow(doc.split()) for doc in cleaned_docs]\n",
    "        self.model = models.LdaModel(bows, self.vec_len, id2word=self.dictionary, chunksize=4000, passes=100, \n",
    "                                         iterations=100, alpha=\"auto\", eta=\"auto\", eval_every=80000\n",
    "                                        )\n",
    "        print(\"topic model generated\")\n",
    "        \n",
    "        # save to file\n",
    "        self.dictionary.save(self.folder + \"/\" + \"dictionary\")\n",
    "        self.model.save(self.folder + \"/\" + \"model\")\n",
    "        \n",
    "    def index_topic_and_video(self, topics, videos, existing_video_index=None):\n",
    "        \"\"\"\n",
    "        Index all documents to get self: topic_index, topic_vec, video_topic_vec and video_vec\n",
    "        \n",
    "        topics: dictionary of topic name and topic texts\n",
    "        videos: dictionary of video name and video subtitles\n",
    "        \"\"\" \n",
    "        # create video_index and indexed_video if no existing video index and indexed video\n",
    "        if existing_video_index is None:\n",
    "            v_counter = 0\n",
    "            for v in videos:\n",
    "                self.video_index[v] = v_counter\n",
    "                self.indexed_video.append(v)\n",
    "                v_counter += 1\n",
    "        else: # load existing video index\n",
    "            self.video_index = existing_video_index[\"video_index\"]\n",
    "            self.indexed_video = existing_video_index[\"indexed_video\"]\n",
    "            v_counter = len(indexed_video)\n",
    "        \n",
    "        # create topic_index and indexed_topic\n",
    "        t_counter = 0\n",
    "        for t in topics:\n",
    "            self.topic_index[t] = t_counter\n",
    "            self.indexed_topic.append(t)\n",
    "            t_counter += 1\n",
    "        \n",
    "        # create topic_vec\n",
    "        self.topic_vec = np.zeros((t_counter, self.vec_len))\n",
    "        for t in topics:\n",
    "            t_vec = self.index_text(topics[t], norm=None, thresh=5)\n",
    "            self.topic_vec[self.topic_index[t], :] = t_vec\n",
    "            \n",
    "        # create video_vec:\n",
    "        self.video_vec = np.zeros((v_counter, self.vec_len))\n",
    "        for v in videos:\n",
    "            v_vec = self.index_text(videos[v], norm=None, thresh=1)\n",
    "            self.video_vec[self.video_index[v], :] = v_vec\n",
    "            \n",
    "        # create video_topic_vec, preserve the original similarity score\n",
    "        self.video_topic_vec = self.norm_dot(self.video_vec, self.topic_vec)\n",
    "\n",
    "        # save self. topic_index, indexed_topic, topic_vec, video_index, indexed_video, video_vec, video_topic_vec\n",
    "        np.save(self.folder + \"/topic_vec\", self.topic_vec)\n",
    "        np.save(self.folder + \"/video_vec\", self.video_vec)\n",
    "        np.save(self.folder + \"/video_topic_vec\", self.video_topic_vec)\n",
    "        with open(self.folder + \"/topic_index.pkl\", 'wb') as f:\n",
    "            pickle.dump(self.topic_index, f)\n",
    "        with open(self.folder + \"/indexed_topic.pkl\", 'wb') as f:\n",
    "            pickle.dump(self.indexed_topic, f)\n",
    "        with open(self.folder + \"/video_index.pkl\", 'wb') as f:\n",
    "            pickle.dump(self.video_index, f)\n",
    "        with open(self.folder + \"/indexed_video.pkl\", 'wb') as f:\n",
    "            pickle.dump(self.indexed_video, f)\n",
    "    \n",
    "    def load_topic_model(self):\n",
    "        \"\"\"\n",
    "        load topic models if no training is needed\n",
    "        \"\"\"\n",
    "        self.dictionary = corpora.Dictionary.load(self.folder + \"/dictionary\")\n",
    "        self.model = models.LdaModel.load(self.folder + \"/model\")\n",
    "        self.vec_len = self.model.num_topics\n",
    "        \n",
    "    def load_topic_video_model(self):\n",
    "        \"\"\"\n",
    "        load topic_index, indexed_topic, topic_vec, video_index, indexed_video, video_vec, video_topic_vec\n",
    "        \"\"\"\n",
    "        self.topic_vec = np.load(self.folder + \"/topic_vec.npy\")\n",
    "        self.video_vec = np.load(self.folder + \"/video_vec.npy\")\n",
    "        self.video_topic_vec = np.load(self.folder + \"/video_topic_vec.npy\")\n",
    "        with open(self.folder + \"/topic_index.pkl\", 'rb') as f:\n",
    "            self.topic_index = pickle.load(f)\n",
    "        with open(self.folder + \"/indexed_topic.pkl\", 'rb') as f:\n",
    "            self.indexed_topic = pickle.load(f)\n",
    "        with open(self.folder + \"/video_index.pkl\", 'rb') as f:\n",
    "            self.video_index = pickle.load(f)\n",
    "        with open(self.folder + \"/indexed_video.pkl\", 'rb') as f:\n",
    "            self.indexed_video = pickle.load(f)\n",
    "        \n",
    "    def index_text(self, text, norm=None, thresh=0.05):\n",
    "        \"\"\"\n",
    "        Index a given string use topic model\n",
    "        \"\"\"\n",
    "        # clean the text\n",
    "        cleaned_text = self.cl.clean(text)\n",
    "\n",
    "        # get topic model index\n",
    "        model_vec = self.model.inference([self.dictionary.doc2bow(cleaned_text.split())])[0][0]\n",
    "        \n",
    "        # topics that has prob lower than thresh would be set to zero\n",
    "        model_vec -= thresh\n",
    "        model_vec[model_vec<0] = 0\n",
    "        \n",
    "        # return zero array if no significant topic possibility\n",
    "        if model_vec.sum() == 0:\n",
    "            return model_vec\n",
    "        \n",
    "        # do norm if necessary\n",
    "        if norm is None:\n",
    "            return model_vec\n",
    "        else:\n",
    "            return model_vec / np.linalg.norm(model_vec, ord=norm)\n",
    "        \n",
    "    def norm_dot(self, a, b):\n",
    "        \"\"\"\n",
    "        A dot operation that is aim to find all cos similarity of each row of each array\n",
    "        \"\"\"\n",
    "        # get per row norm for each array\n",
    "        norm_a = np.linalg.norm(a, ord=2, axis=1).reshape(-1, 1)\n",
    "        norm_b = np.linalg.norm(b, ord=2, axis=1).reshape(-1, 1)\n",
    "        \n",
    "        # get similarity by doting normalized array rows\n",
    "        sim = np.dot(a / norm_a, (b / norm_b).T)\n",
    "        \n",
    "        np.nan_to_num(sim, copy=False)\n",
    "        \n",
    "        return sim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the subject model to have the same index as interest model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from anytree import Node, RenderTree\n",
    "from anytree.importer import DictImporter\n",
    "importer = DictImporter()\n",
    "# load subjects as topics\n",
    "topics = {}\n",
    "with open(\"../text_resource/tree.json\", \"r\") as f:\n",
    "    tree = importer.import_(json.load(f))\n",
    "with open(\"../text_resource/node2text.json\", \"r\") as f:\n",
    "    node2text = json.load(f)\n",
    "\n",
    "leaf_nodes = []\n",
    "def get_leaf_node(node):\n",
    "    if node.is_leaf:\n",
    "        leaf_nodes.append(node)\n",
    "    else:\n",
    "        for child in node.children:\n",
    "            get_leaf_node(child)\n",
    "get_leaf_node(tree)\n",
    "\n",
    "for node in leaf_nodes:\n",
    "    text = node2text[node.name]\n",
    "    topics[node.name] = text\n",
    "    \n",
    "# prepare documents of videos\n",
    "with open(\"../text_resource/cleaned_subtitles.json\", \"r\") as f:\n",
    "    o_videos = json.load(f)\n",
    "# clean up names\n",
    "videos = {}\n",
    "for ov in o_videos:\n",
    "    v = re.sub(\"(.*/)\", \"\", ov)\n",
    "    v = re.sub(\".en.json\", \"\", v)\n",
    "    videos[(v[:-12], v[-11:])] = o_videos[ov]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-12-01 19:30:15,080 : INFO : loading Phraser object from ../text_cleaner_models_without_subjects//bigram\n",
      "2018-12-01 19:30:15,092 : INFO : loaded ../text_cleaner_models_without_subjects//bigram\n",
      "2018-12-01 19:30:15,094 : INFO : loading Phraser object from ../text_cleaner_models_without_subjects//trigram\n",
      "2018-12-01 19:30:15,103 : INFO : loaded ../text_cleaner_models_without_subjects//trigram\n",
      "2018-12-01 19:30:15,105 : INFO : loading Dictionary object from ./asym_150_both/dictionary\n",
      "2018-12-01 19:30:15,117 : INFO : loaded ./asym_150_both/dictionary\n",
      "2018-12-01 19:30:15,120 : INFO : loading LdaModel object from ./asym_150_both/model\n",
      "2018-12-01 19:30:15,123 : INFO : loading expElogbeta from ./asym_150_both/model.expElogbeta.npy with mmap=None\n",
      "2018-12-01 19:30:15,136 : INFO : setting ignored attribute id2word to None\n",
      "2018-12-01 19:30:15,139 : INFO : setting ignored attribute state to None\n",
      "2018-12-01 19:30:15,142 : INFO : setting ignored attribute dispatcher to None\n",
      "2018-12-01 19:30:15,144 : INFO : loaded ./asym_150_both/model\n",
      "2018-12-01 19:30:15,146 : INFO : loading LdaModel object from ./asym_150_both/model.state\n",
      "2018-12-01 19:30:15,276 : INFO : loaded ./asym_150_both/model.state\n"
     ]
    }
   ],
   "source": [
    "interest_t = InterestTrainer()\n",
    "interest_t.load_topic_model()\n",
    "interest_t.load_topic_video_model()\n",
    "existing_video_index = {}\n",
    "existing_video_index[\"indexed_video\"] = interest_t.indexed_video\n",
    "existing_video_index[\"video_index\"] = interest_t.video_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-12-01 19:30:15,790 : INFO : loading Phraser object from ../text_cleaner_models_with_subjects//bigram\n",
      "2018-12-01 19:30:15,799 : INFO : loaded ../text_cleaner_models_with_subjects//bigram\n",
      "2018-12-01 19:30:15,801 : INFO : loading Phraser object from ../text_cleaner_models_with_subjects//trigram\n",
      "2018-12-01 19:30:15,808 : INFO : loaded ../text_cleaner_models_with_subjects//trigram\n",
      "2018-12-01 19:30:15,810 : INFO : loading Dictionary object from ./subject_models/dictionary\n",
      "2018-12-01 19:30:15,814 : INFO : loaded ./subject_models/dictionary\n",
      "2018-12-01 19:30:15,816 : INFO : loading LdaModel object from ./subject_models/model\n",
      "2018-12-01 19:30:15,818 : INFO : loading expElogbeta from ./subject_models/model.expElogbeta.npy with mmap=None\n",
      "2018-12-01 19:30:15,821 : INFO : setting ignored attribute id2word to None\n",
      "2018-12-01 19:30:15,823 : INFO : setting ignored attribute dispatcher to None\n",
      "2018-12-01 19:30:15,825 : INFO : setting ignored attribute state to None\n",
      "2018-12-01 19:30:15,826 : INFO : loaded ./subject_models/model\n",
      "2018-12-01 19:30:15,828 : INFO : loading LdaModel object from ./subject_models/model.state\n",
      "2018-12-01 19:30:15,840 : INFO : loaded ./subject_models/model.state\n",
      "/Users/andywu/anaconda3/envs/tensorflow/lib/python3.5/site-packages/ipykernel_launcher.py:184: RuntimeWarning: invalid value encountered in true_divide\n"
     ]
    }
   ],
   "source": [
    "subject_t = SubjectTrainer()\n",
    "subject_t.load_topic_model()\n",
    "subject_t.index_topic_and_video(topics, videos, existing_video_index=existing_video_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subject_t.indexed_video == interest_t.indexed_video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class InterestVectorizer():\n",
    "    \"\"\"\n",
    "    The class for training topic model\n",
    "    \"\"\"\n",
    "    def __init__(self, folder=\"./asym_150_both\", cl_folder=\"../text_cleaner_models_without_subjects\", \n",
    "                 existing_video_index=None\n",
    "                ):\n",
    "        \"\"\"\n",
    "        Initialize and load all models\n",
    "        \"\"\"\n",
    "        # init model folder\n",
    "        self.folder = folder\n",
    "\n",
    "        # load topic models if no training is needed\n",
    "        self.dictionary = corpora.Dictionary.load(self.folder + \"/dictionary\")\n",
    "        self.model = models.LdaModel.load(self.folder + \"/model\")\n",
    "        self.vec_len = self.model.num_topics\n",
    "        \n",
    "        # load topic_index, indexed_topic, topic_vec, video_index, indexed_video, video_vec, video_topic_vec\n",
    "        self.topic_vec = np.load(self.folder + \"/topic_vec.npy\")\n",
    "        self.video_vec = np.load(self.folder + \"/video_vec.npy\")\n",
    "        self.video_topic_vec = np.load(self.folder + \"/video_topic_vec.npy\")\n",
    "        self.topic_video_vec = self.video_topic_vec.T\n",
    "        with open(self.folder + \"/topic_index.pkl\", 'rb') as f:\n",
    "            self.topic_index = pickle.load(f)\n",
    "        with open(self.folder + \"/indexed_topic.pkl\", 'rb') as f:\n",
    "            self.indexed_topic = pickle.load(f)\n",
    "        if existing_video_index is None:\n",
    "            with open(self.folder + \"/video_index.pkl\", 'rb') as f:\n",
    "                self.video_index = pickle.load(f)\n",
    "            with open(self.folder + \"/indexed_video.pkl\", 'rb') as f:\n",
    "                self.indexed_video = pickle.load(f)\n",
    "        else:\n",
    "            self.video_index = existing_video_index[\"video_index\"]\n",
    "            self.indexed_video = existing_video_index[\"indexed_video\"]\n",
    "        \n",
    "        # load string cleaner\n",
    "        self.cl = TextCleaner(folder=cl_folder)\n",
    "    \n",
    "    def score_video_based_on_interest_vector(self, interest_vec, thresh=0.05):\n",
    "        \"\"\"\n",
    "        With the input interest vector, return a score for all the videos\n",
    "        Removing video whose similarity to the topic is less then thresh\n",
    "        Be advised, do not normalize video topic vec as we are not summing the simlarities of videos\n",
    "            to different \n",
    "        \"\"\"\n",
    "        if interest_vec.sum() == 0: # normally distributed interest if no interest is registered\n",
    "            normed_interest_vector = np.ones_like(normed_interest_vector)\n",
    "            normed_interest_vector /= normed_interest_vector.sum()\n",
    "        else:\n",
    "            normed_interest_vector = interest_vec / interest_vec.sum()\n",
    "        video_score = np.dot(self.video_topic_vec, normed_interest_vector).reshape(-1)\n",
    "        \n",
    "        return video_score\n",
    "    \n",
    "    def index_text(self, text, norm=1, thresh=0.05):\n",
    "        \"\"\"\n",
    "        Index a given string use topic model\n",
    "        \"\"\"\n",
    "        # clean the text\n",
    "        cleaned_text = self.cl.clean(text)\n",
    "\n",
    "        # get topic model index\n",
    "        model_vec = self.model.inference([self.dictionary.doc2bow(cleaned_text.split())])[0][0]\n",
    "        \n",
    "        # topics that has prob lower than thresh would be set to zero\n",
    "        model_vec -= thresh\n",
    "        model_vec[model_vec<0] = 0\n",
    "        \n",
    "        # return zero array if no significant topic possibility\n",
    "        if model_vec.sum() == 0:\n",
    "            return model_vec\n",
    "        \n",
    "        # do norm if necessary\n",
    "        if norm is None:\n",
    "            return model_vec\n",
    "        else:\n",
    "            return model_vec / np.linalg.norm(model_vec, ord=norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class SubjectVectorizer():\n",
    "    \"\"\"\n",
    "    The class for training topic model\n",
    "    \"\"\"\n",
    "    def __init__(self, folder=\"./subject_models\", cl_folder=\"../text_cleaner_models_with_subjects/\", \n",
    "                 existing_video_index=None\n",
    "                ):\n",
    "        \"\"\"\n",
    "        Initialize and load all models\n",
    "        \"\"\"\n",
    "        # init model folder\n",
    "        self.folder = folder\n",
    "\n",
    "        # load topic models if no training is needed\n",
    "        self.dictionary = corpora.Dictionary.load(self.folder + \"/dictionary\")\n",
    "        self.model = models.LdaModel.load(self.folder + \"/model\")\n",
    "        self.vec_len = self.model.num_topics\n",
    "        \n",
    "        # load topic_index, indexed_topic, topic_vec, video_index, indexed_video, video_vec, video_topic_vec\n",
    "        self.topic_vec = np.load(self.folder + \"/topic_vec.npy\")\n",
    "        self.video_vec = np.load(self.folder + \"/video_vec.npy\")\n",
    "        self.video_topic_vec = np.load(self.folder + \"/video_topic_vec.npy\")\n",
    "        self.topic_video_vec = self.video_topic_vec.T\n",
    "        with open(self.folder + \"/topic_index.pkl\", 'rb') as f:\n",
    "            self.topic_index = pickle.load(f)\n",
    "        with open(self.folder + \"/indexed_topic.pkl\", 'rb') as f:\n",
    "            self.indexed_topic = pickle.load(f)\n",
    "        if existing_video_index is None:\n",
    "            with open(self.folder + \"/video_index.pkl\", 'rb') as f:\n",
    "                self.video_index = pickle.load(f)\n",
    "            with open(self.folder + \"/indexed_video.pkl\", 'rb') as f:\n",
    "                self.indexed_video = pickle.load(f)\n",
    "        else:\n",
    "            self.video_index = existing_video_index[\"video_index\"]\n",
    "            self.indexed_video = existing_video_index[\"indexed_video\"]\n",
    "        \n",
    "        # load string cleaner\n",
    "        self.cl = TextCleaner(folder=cl_folder)\n",
    "    \n",
    "    def score_video_based_on_topic(self, topics, thresh=0.6):\n",
    "        \"\"\"\n",
    "        With the input topics, return a score for all the videos\n",
    "        Removing video whose similarity to the topic is less then thresh\n",
    "        \"\"\"\n",
    "        video_score_sum = np.zeros(len(self.indexed_video))\n",
    "        for t in topics:\n",
    "            ti = self.topic_index[t]\n",
    "            video_score = self.topic_video_vec[ti].copy()\n",
    "            video_score[video_score<thresh] = 0\n",
    "            video_score_sum += video_score\n",
    "        video_score_sum[video_score_sum<thresh] = 0\n",
    "            \n",
    "        return video_score_sum / len(topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class VideoVectorizer():\n",
    "    def __init__(self, folder=\".\"):\n",
    "        \"\"\"\n",
    "        Load from folder vectorizer for interest and subject\n",
    "        \"\"\"\n",
    "        # load vectorizer\n",
    "        self.interest = InterestVectorizer(folder=folder + \"/asym_150_both\", cl_folder=folder + \"/text_cleaner_models_without_subjects\")\n",
    "        self.subject = SubjectVectorizer(folder=folder + \"/subject_models\", cl_folder=folder + \"/text_cleaner_models_with_subjects\")\n",
    "        \n",
    "        # get the common video index\n",
    "        self.indexed_video = self.interest.indexed_video\n",
    "        self.video_index = self.subject.video_index\n",
    "        \n",
    "    def update_interest_vector(self, prev_interest_vec, prev_video, update_constant=0.1):\n",
    "        \"\"\"\n",
    "        update interest vector with EMS\n",
    "        \"\"\"\n",
    "        prev_video_interest_vec = self.interest.video_topic_vec[self.video_index[prev_video]]\n",
    "        \n",
    "        interest_vec = update_constant * (prev_video_interest_vec - prev_interest_vec) + prev_interest_vec\n",
    "        \n",
    "        return interest_vec\n",
    "        \n",
    "    def get_ranked_video(self, subjects, interest_vec, subject_weight=0.8, subject_mask_value=0.1, thresh=0):\n",
    "        # get score for each video based on topics and interests\n",
    "        interest_score = self.interest.score_video_based_on_interest_vector(interest_vec)\n",
    "        subject_score = self.subject.score_video_based_on_topic(subjects)\n",
    "        \n",
    "        # get the final score, NB video that does not match a subject would not be presented\n",
    "        final_score = subject_weight * subject_score + (1 - subject_weight) * interest_score\n",
    "        # get subject mask to mask the final result\n",
    "        subject_mask = subject_score.copy()\n",
    "        subject_mask[subject_mask>0] = 1\n",
    "        subject_mask[subject_mask==0] = subject_mask_value\n",
    "        # get finally masked result\n",
    "        final_score *= subject_mask\n",
    "        \n",
    "        # give ranked url and title out\n",
    "        sorted_score = sorted(enumerate(final_score), key=lambda x:x[1], reverse=True)\n",
    "        \n",
    "        ranked_video = []\n",
    "        for index, score in sorted_score:\n",
    "            if score < thresh:\n",
    "                break\n",
    "            ranked_video.append((self.indexed_video[index], score))\n",
    "        return ranked_video"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing py package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from VideoVectorizer import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-12-01 22:09:03,089 : INFO : loading Dictionary object from ./asym_150_both/dictionary\n",
      "2018-12-01 22:09:03,110 : INFO : loaded ./asym_150_both/dictionary\n",
      "2018-12-01 22:09:03,114 : INFO : loading LdaModel object from ./asym_150_both/model\n",
      "2018-12-01 22:09:03,118 : INFO : loading expElogbeta from ./asym_150_both/model.expElogbeta.npy with mmap=None\n",
      "2018-12-01 22:09:03,134 : INFO : setting ignored attribute id2word to None\n",
      "2018-12-01 22:09:03,137 : INFO : setting ignored attribute state to None\n",
      "2018-12-01 22:09:03,140 : INFO : setting ignored attribute dispatcher to None\n",
      "2018-12-01 22:09:03,142 : INFO : loaded ./asym_150_both/model\n",
      "2018-12-01 22:09:03,145 : INFO : loading LdaModel object from ./asym_150_both/model.state\n",
      "2018-12-01 22:09:03,285 : INFO : loaded ./asym_150_both/model.state\n",
      "2018-12-01 22:09:03,345 : INFO : loading Phraser object from ./text_cleaner_models_without_subjects/bigram\n",
      "2018-12-01 22:09:03,359 : INFO : loaded ./text_cleaner_models_without_subjects/bigram\n",
      "2018-12-01 22:09:03,361 : INFO : loading Phraser object from ./text_cleaner_models_without_subjects/trigram\n",
      "2018-12-01 22:09:03,371 : INFO : loaded ./text_cleaner_models_without_subjects/trigram\n",
      "2018-12-01 22:09:03,373 : INFO : loading Dictionary object from ./subject_models/dictionary\n",
      "2018-12-01 22:09:03,378 : INFO : loaded ./subject_models/dictionary\n",
      "2018-12-01 22:09:03,380 : INFO : loading LdaModel object from ./subject_models/model\n",
      "2018-12-01 22:09:03,383 : INFO : loading expElogbeta from ./subject_models/model.expElogbeta.npy with mmap=None\n",
      "2018-12-01 22:09:03,388 : INFO : setting ignored attribute id2word to None\n",
      "2018-12-01 22:09:03,390 : INFO : setting ignored attribute dispatcher to None\n",
      "2018-12-01 22:09:03,391 : INFO : setting ignored attribute state to None\n",
      "2018-12-01 22:09:03,393 : INFO : loaded ./subject_models/model\n",
      "2018-12-01 22:09:03,395 : INFO : loading LdaModel object from ./subject_models/model.state\n",
      "2018-12-01 22:09:03,412 : INFO : loaded ./subject_models/model.state\n",
      "2018-12-01 22:09:03,445 : INFO : loading Phraser object from ./text_cleaner_models_with_subjects/bigram\n",
      "2018-12-01 22:09:03,459 : INFO : loaded ./text_cleaner_models_with_subjects/bigram\n",
      "2018-12-01 22:09:03,461 : INFO : loading Phraser object from ./text_cleaner_models_with_subjects/trigram\n",
      "2018-12-01 22:09:03,469 : INFO : loaded ./text_cleaner_models_with_subjects/trigram\n"
     ]
    }
   ],
   "source": [
    "vv = VideoVectorizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# get video ranks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "topics are:  ['sub_Gravitational fields']\n",
      "interest is:  Visiting and Travel\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(('Why Are Astronauts Weightless', 'iQOHRKKNNLQ'), 0.4768162680938836),\n",
       " (('Our Definition For “Moon” Is Broken (Collab. w_ MinutePhysics)',\n",
       "   'pAI1N96t8Vk'),\n",
       "  0.4753106636848026),\n",
       " (('What Is a Field - Instant Egghead #42', '7BK166SL-ig'),\n",
       "  0.47235847019149185),\n",
       " ((\"Best Film on Newton's Third Law. Ever.\", '8bTdMmNZm2M'),\n",
       "  0.46854150718677434),\n",
       " (('Why Does the Moon Orbit Earth', 'zN6kCa6xi9k'), 0.46307715482972467),\n",
       " (('Is There Gravity In Space', 'd57C2drB_wc'), 0.45150551371147835),\n",
       " (('The Tides explained in ten seconds', 'mVJEi-PkkaY'), 0.4459317506965165),\n",
       " (('Does Earth Have A Second Moon', 'rmQepa1qnI0'), 0.44552773522367384),\n",
       " (('How Big is the Moon MM#1', 'Tqt9hZcWhJM'), 0.43568792215630253),\n",
       " (('Is There Poop on the Moon ft. Smarter Every Day', 'QNP8wy3S_kY'),\n",
       "  0.43518315250254885),\n",
       " (('LONELY.', '_QPcclYWOr4'), 0.42679270621174176),\n",
       " (('How Texting Can Ruin Relationships', 'DzaU-TinoZQ'), 0.4250347792168338),\n",
       " (('Calculating Gravitational Attraction', 'SN1Q5ru2fI0'), 0.4232031695728859),\n",
       " (('The Moon Is So Damn Awesome', '4PSh22E5SSQ'), 0.4226753467640202),\n",
       " (('Who Owns The Moon', 'Ks8WH3xUo_E'), 0.42046488435607055),\n",
       " (('This Is How You Can Tell A Full Moon Is Coming', 'TZEn4Y3_GLo'),\n",
       "  0.41585099457090946),\n",
       " (('Explaining Lunar Eclipses and the SUPER BLOOD MOON!', '2yb5aqdIFco'),\n",
       "  0.4125041722008601),\n",
       " ((\"NASA Solved The Mystery Of The Moon's Strange Glow!\", 'q8_ecxrNdZQ'),\n",
       "  0.4097407490316306),\n",
       " (('Volcano Lightning - How Does It Happen', 'A_FxTricy0c'),\n",
       "  0.40805835875260926),\n",
       " (('What Causes The Phases Of The Moon', 'Jip3BbZBpsM'), 0.4070868618239056),\n",
       " (('Real World Telekinesis (feat. Neil Turok)', 'NMgcX8UNIGY'),\n",
       "  0.4014089846592947),\n",
       " (('Does The Moon Really Orbit The Earth', '3cJ3AemeUFM'), 0.3989473299970465),\n",
       " (('Indonesian Earthquakes', '6pwlMHpeOto'), 0.39596573541634084),\n",
       " (('Sprites, Jets, and Glowing Balls - The Science of Lightning',\n",
       "   'fzNk4w2k2h0'),\n",
       "  0.3948697624952021),\n",
       " (('The Tides', 'gftT3wHJGtg'), 0.3947295500740541),\n",
       " (('What is Sea Level', 'q65O3qA0-n4'), 0.39452703592398464),\n",
       " (('How Far Away is the Moon (The Scale of the Universe)', 'Bz9D6xba9Og'),\n",
       "  0.39420278857444174),\n",
       " (('Fun Facts About the Moon, from Kendall', 'EeiAE5HKXBY'),\n",
       "  0.39153803850707575),\n",
       " (('Long-Distance Relationships Might Be Better', 'GdnldWXTBzo'),\n",
       "  0.38808385234833687),\n",
       " (('Electromagnetism - Electrostatic Force - The Four Fundamental Forces of Physics #4a',\n",
       "   'GMnsZuEE_m8'),\n",
       "  0.387390910568925),\n",
       " (('Tidal Locking _ Why Do We Only See One Side of the Moon', '6jUpX7J7ySo'),\n",
       "  0.38499198924355355),\n",
       " (('Who Is NASA’s ‘Forgotten Astronaut’', '5H5RQJ94tWU'), 0.3843933365991441),\n",
       " (('Do Essential Oils Really Work And Why', '5MJpurZ9ShI'),\n",
       "  0.3836348029675748),\n",
       " (('How to catch a Dwarf Planet -- Triton MM#3', 'cR9uphgMZ8U'),\n",
       "  0.3760583245792053),\n",
       " (('What Is Gravity', 'mezkHBPLZ4A'), 0.3757696669045368),\n",
       " (('Gravitation - The Four Fundamental Forces of Physics #3', 'yhG_ArxmwRM'),\n",
       "  0.37532083021406865),\n",
       " (('WHAT IS THIS LINE (on my Super Blue Blood Moon Photo) - Smarter Every Day 188',\n",
       "   '9reizHjwuNY'),\n",
       "  0.3743257407400689),\n",
       " (('Water on the Moon', 'hbXDLKFkjm0'), 0.371293216360043),\n",
       " (('Can Astronauts Return to Earth Without Russia', 'HfFRWkNQf34'),\n",
       "  0.36529617054600466),\n",
       " ((\"What Happens When You're Struck By Lightning\", 'fhjx6lGTDhw'),\n",
       "  0.3651742431043561),\n",
       " (('What is Déjà Vu!', 'ut8mYGi0YRs'), 0.362913345833845),\n",
       " (('The Mystery Of The Moon Is Finally Solved!', 'GW2fU1uxwQY'),\n",
       "  0.36074319884479644),\n",
       " (('Invisible, Radioactive DARK Lightning', 'l-UT1UkZsP8'), 0.358689716418636),\n",
       " (('Great Minds - Benjamin Franklin - Founding Nerd', 'Ki9mY6gMFpA'),\n",
       "  0.3584938328165655),\n",
       " (('Is a Blood Moon a Sign Of the Apocalypse', '6ACta1B-B50'),\n",
       "  0.35625299773567487),\n",
       " (('Lunar Impact!', 'ZpDHk2KeKFU'), 0.3558512263401376),\n",
       " (('Can Humans Control Lightning', 'eBzxn2LEJoE'), 0.3534341044017491),\n",
       " (('3 Ways Pi Can Explain Practically Everything', 'zMInC0Dk9l0'),\n",
       "  0.35216235373682947),\n",
       " ((\"Volcanic Lightning - Because Exploding Mountains Aren't Bad Enough\",\n",
       "   'T2rhsi-uSFI'),\n",
       "  0.3517947119039312),\n",
       " (('How Apollo 8 Survived the Risky Trip to the Far Side of the Moon _ Apollo',\n",
       "   'p_gW0g_h6rk'),\n",
       "  0.35164320016301864),\n",
       " (('Justin Bieber - GAME TRAILER (Parody)', 'eEFsnP3nUR4'),\n",
       "  0.35109827031523105),\n",
       " (('What Would Happen If Gravity Stopped', 'xIfb4NZrmnc'), 0.3509163946650756),\n",
       " (('Gazing vs Staring, As Explained by Dr. Robert Epstein', 'JTQTDfxBaoo'),\n",
       "  0.3457118701820554),\n",
       " (('Should We Worry About An Avalanche On An Asteroid', 'Mp14j8K37BY'),\n",
       "  0.34400605478597934),\n",
       " (('Apollo 10 Almost Crashed Into the Moon _ Apollo', 's8MGV2hGqhs'),\n",
       "  0.34196139382118584),\n",
       " ((\"Will the Moon Ever Leave the Earth's Orbit\", 'IM_euz9PUiw'),\n",
       "  0.3399788426005812),\n",
       " (('China Has a Rover on the Moon & Here’s What It Found', 'n2G1z4NMg6k'),\n",
       "  0.3399673688822455),\n",
       " (('Our Moon Might Be Made Up Of Many Smaller Moons', '-k6mz9qle40'),\n",
       "  0.3397553612278655),\n",
       " (('Why The Earth Needs Volcanic Eruptions', '2zthMCD_m50'),\n",
       "  0.33806374222193414),\n",
       " (('How To Tell If Someone Is Lying To You', 'z4f48M999Rk'),\n",
       "  0.33663694573371894),\n",
       " (('Why Does Glitter Stick to Everything', '8W2zPD2Mc9M'), 0.3345286750509105),\n",
       " (('How Long To Fall Through The Earth', 'urQCmMiHKQk'), 0.33344083423171517),\n",
       " (('Why People Believe Jesus Had a Wife', 'N2Ws_x7C8JI'), 0.3326942095841861),\n",
       " (('The Buttered Coffee Experiment', 'JzUW6iid-Ks'), 0.3325056730607522),\n",
       " (('What Happens If A Plane Gets Struck By Lightning', 'OXrqTUVN7G8'),\n",
       "  0.33199907352302765),\n",
       " (('What Would Happen If Earth Lost Its Gravitational Field (Part 2 of 3)',\n",
       "   'lrP8ab5_-d8'),\n",
       "  0.32914911933022073),\n",
       " (('How Big Is The Sun', 'u70lZSMP9Bo'), 0.3273191477527484),\n",
       " (('Found - The BIGGEST Volcano Out There!', 'xplpnLeeJxI'),\n",
       "  0.3266875511569099),\n",
       " (('Mark and Michael - Vsauce BLOOPERS', 'm_icISNqoS8'), 0.32651328711183436),\n",
       " (('What if the Moon was a Disco Ball', 'w8I25H3bnNw'), 0.3251775218032947),\n",
       " (('Can Humans Really Feel Temperature', 'yXT012us9ng'), 0.32369708918659806),\n",
       " (('What Happened To The Flags On The Moon', 'aJrIWXsefoA'),\n",
       "  0.32367599988302614),\n",
       " (('Welding in Space', 'Y2nQ8isf55s'), 0.32351131096495406),\n",
       " ((\"Lightning Hit Apollo 12 Mid-Flight (Twice) - Here's What Happened Next\",\n",
       "   '9oda7FnBJzY'),\n",
       "  0.32217316900272314),\n",
       " (('What is a Force', 'GmlMV7bA0TM'), 0.31986647970167675),\n",
       " (('This Is How the Apollo Program Began', '2uyTgdzH7u4'), 0.3166031450042055),\n",
       " (('Attractive Friends Make You Hotter', '-lYWmYJ2gsY'), 0.3145495156492711),\n",
       " ((\"NASA Just Tested The 'Impossible Drive' - Does It Work\", 'xWfeE7l1Wxo'),\n",
       "  0.31399214284996335),\n",
       " (('Why Gravity Fluctuates on the Moon', 'Pt2w9Dz4CDM'), 0.3121897756605468),\n",
       " (('How Do We Control Gravity in Space (Part 3 of 3)', 'pUsiorDJ_cM'),\n",
       "  0.3087652599530628),\n",
       " (('Which Way Is Down', 'Xc4xYacTu-E'), 0.30510576342157736),\n",
       " (('022 Re - Akbar - Inactivation of V-gated Sodium Channels', 'zH7s4tywHX0'),\n",
       "  0.3030870257809305),\n",
       " (('Footnote † - Unstable Equilibrium', 'plUboQZgkng'), 0.3027626311969683),\n",
       " (('NASA Brings WiFi To Space', '9r9UwF7fBOA'), 0.3026411559094846),\n",
       " (('Does The Moon Really Control The Tides', 'EYQ54bSrtGI'),\n",
       "  0.30117726493000524),\n",
       " ((\"'The God Particle' - The Higgs Boson\", '1_HrQVhgbeo'),\n",
       "  0.30025355331306675)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topics = vv.subject.indexed_topic[10:11]\n",
    "print(\"topics are: \", topics)\n",
    "\n",
    "index = 30\n",
    "interest_vec = np.zeros_like(vv.interest.video_topic_vec[0])\n",
    "interest_vec[index] = 1\n",
    "print(\"interest is: \", vv.interest.indexed_topic[index])\n",
    "\n",
    "rank = vv.get_ranked_video(topics, interest_vec, subject_weight=0.5, thresh=0.1)\n",
    "rank"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# update interest vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9.86522330e-01, 1.37180339e-04, 2.96458314e-04, 3.27611181e-05,\n",
       "       1.28036671e-03, 1.11712140e-03, 7.34916968e-05, 6.82541462e-06,\n",
       "       1.21089875e-03, 3.62656553e-02, 1.62016043e-05, 1.47018327e-04,\n",
       "       3.93463939e-04, 5.36163756e-03, 1.79165231e-03, 8.27099208e-03,\n",
       "       1.03945717e-03, 2.25911788e-03, 2.09346629e-02, 5.71284230e-04,\n",
       "       0.00000000e+00, 3.58201516e-04, 7.93990969e-03, 4.23049602e-03,\n",
       "       7.47967202e-04, 9.20865848e-04, 1.73541606e-03, 7.11531135e-02,\n",
       "       9.45783171e-05, 1.70179438e-05, 2.23952506e-03, 2.83625824e-03,\n",
       "       2.01359949e-03, 8.92987120e-04, 7.67562046e-04, 8.76020840e-02,\n",
       "       1.20735937e-02, 5.26675576e-05, 0.00000000e+00, 7.61999294e-03,\n",
       "       2.12843647e-03, 5.78043329e-04, 2.35864996e-03, 2.32065223e-02,\n",
       "       2.30981782e-03, 6.72781318e-03, 1.59164327e-03, 1.62465830e-03,\n",
       "       9.76286465e-04, 1.61203363e-03, 1.23127857e-02, 6.11358770e-05,\n",
       "       0.00000000e+00, 4.65810833e-03, 5.86727402e-05, 1.66928883e-02,\n",
       "       1.19252130e-02, 0.00000000e+00, 2.42170822e-03, 5.73957405e-03,\n",
       "       4.03483633e-02, 0.00000000e+00, 9.61106904e-03, 3.33772713e-04,\n",
       "       1.17526109e-04, 1.45047486e-02, 3.66065102e-03, 2.49190403e-04,\n",
       "       9.90223116e-06, 1.30025376e-03, 1.54099841e-03, 0.00000000e+00,\n",
       "       5.59757363e-03, 6.20587888e-03, 3.92834081e-04, 4.89688996e-03,\n",
       "       2.33515500e-02, 1.25851041e-03, 7.07471218e-04, 2.49147261e-06,\n",
       "       1.15772348e-03, 1.31398738e-02, 8.48813145e-03, 1.58074755e-03,\n",
       "       5.24697444e-03, 4.61008425e-03, 0.00000000e+00, 1.41992647e-03,\n",
       "       5.05390678e-03, 0.00000000e+00, 4.27648849e-05, 1.65082744e-03,\n",
       "       2.99564704e-05, 0.00000000e+00, 0.00000000e+00, 3.18541826e-05,\n",
       "       7.77148989e-03, 4.28604366e-03, 2.83443498e-03, 6.06813670e-04,\n",
       "       4.20813764e-03, 8.76660047e-04, 1.58758098e-02, 1.42818525e-02,\n",
       "       7.67607598e-03, 1.94756900e-02, 0.00000000e+00, 2.27841950e-02,\n",
       "       2.57868533e-03, 1.49767261e-06, 3.07581089e-03, 7.67977289e-03,\n",
       "       9.04269395e-04, 1.28539440e-03, 3.33930192e-03, 1.90233596e-03,\n",
       "       7.87621307e-04, 1.88741172e-05, 0.00000000e+00, 5.64163181e-03,\n",
       "       7.32305573e-04, 0.00000000e+00, 6.04851946e-04, 0.00000000e+00,\n",
       "       1.63274362e-05, 4.54407297e-03, 1.76689931e-05, 7.77493212e-04,\n",
       "       6.25088160e-03, 6.25829203e-02, 2.29124359e-02, 6.62370300e-04,\n",
       "       3.46297150e-03, 2.81420006e-03, 2.97473558e-04, 8.23395110e-05,\n",
       "       1.01760800e-02, 1.27064357e-05, 0.00000000e+00, 4.31502307e-03,\n",
       "       2.32488557e-02, 3.46500976e-04, 2.41562953e-03, 3.57407890e-05,\n",
       "       0.00000000e+00, 1.00323891e-02, 4.71846181e-03, 2.37820494e-02,\n",
       "       2.25368442e-02, 0.00000000e+00, 1.78623396e-03, 1.11513005e-03,\n",
       "       1.28713874e-04, 4.26475242e-05, 2.58695364e-03, 4.68328635e-05,\n",
       "       1.09714516e-02, 0.00000000e+00, 6.21725808e-03, 1.24000998e-03,\n",
       "       3.44262587e-04, 4.35483735e-04, 2.15265435e-04, 1.26224331e-02,\n",
       "       3.31674695e-04, 1.70520743e-03, 1.75565179e-02, 9.37162471e-03,\n",
       "       7.50079760e-03, 2.77575507e-03, 0.00000000e+00, 0.00000000e+00,\n",
       "       2.45262678e-05, 0.00000000e+00, 9.67139711e-03, 0.00000000e+00,\n",
       "       2.46773792e-02, 9.91424752e-04, 6.71481677e-04, 8.53835813e-03])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vv.update_interest_vector(interest_vec, prev_video=('What Your Drink Says About Your Politics', 'rdoUojbCfjk'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
